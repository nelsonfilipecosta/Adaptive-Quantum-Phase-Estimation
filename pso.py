import numpy as np
import random
import statistics
import generate
import aqem


def optimization(K, N, P, G, R, threshold, alpha, beta, w, vmax, phi, input, mu, sigma, loss, visibility):

    '''Particle Swarm Optimization. This function returns the best policy generated by the PSO algorithm.'''

    position = np.array([np.array([np.array([0. for i in range(N)]) for j in range(P)]) for k in range(G)])
    velocity = np.array([np.array([np.array([0. for i in range(N)]) for j in range(P)]) for k in range(G)])

    for i in range(P):
        position[0][i] = np.array(generate.policy(N))

    outcome = np.array([np.array([0. for i in range(P)]) for j in range(G)])

    best_pos = np.array([np.array([0. for i in range(N)]) for j in range(P)])
    best_val = np.array([0. for i in range(P)])

    aux = 1000
    gbest = 0

    count = 0

    for g in range(G-1):

        print("Generation:", g)

        aux_counter = 0

        if g % 10 == 0 and g > 0:
            vmax = vmax / 2

        for i in range(P):
        
            outcome[g][i] = aqem.simulate(K, N, R, phi, input, position[g][i], mu, sigma, loss, visibility)

            if g == 0:                                                                                              
                best_val[i] = outcome[g][i]
                best_pos[i] = position[g][i]

            if g > 0:
                if outcome[g][i] < best_val[i]:
                    best_val[i] = outcome[g][i]
                    best_pos[i] = position[g][i]

            if outcome[g][i] < aux:
                aux = outcome[g][i]
                gbest = i

        for i in range(P):
            for j in range(N):
                
                a = best_pos[i][j]-position[g][i][j]

                if a > 1*np.pi:
                    a = a - 2*np.pi
                
                if a < -1*np.pi:
                    a = a + 2*np.pi

                b = best_pos[gbest][j]-position[g][i][j]

                if b > 1*np.pi:
                    b = b - 2*np.pi
                
                if b < -1*np.pi:
                    b = b + 2*np.pi
                
                velocity[g+1][i][j] = velocity[g][i][j] + alpha*random.uniform(0,1)*a + beta*random.uniform(0,1)*b

                position[g+1][i][j] = position[g][i][j] + w * velocity[g+1][i][j]

                if position[g+1][i][j] < 0:
                    a = abs(position[g+1][i][j])
                    b = a // (2*np.pi) + 1
                    position[g+1][i][j] = 2*b*np.pi - a

                if position[g+1][i][j] >= 2*np.pi:
                    a = position[g+1][i][j]
                    b = a // (2*np.pi)
                    position[g+1][i][j] = a - 2*b*np.pi

                if velocity[g+1][i][j] <= -2*np.pi:
                    a = velocity[g+1][i][j]
                    b = a // (2*np.pi) + 1
                    velocity[g+1][i][j] = a - 2*b*np.pi

                if velocity[g+1][i][j] >= 2*np.pi:
                    a = velocity[g+1][i][j]
                    b = a // (2*np.pi)
                    velocity[g+1][i][j] = a - 2*b*np.pi

                if velocity[g+1][i][j] > 1*np.pi:
                    velocity[g+1][i][j] = velocity[g+1][i][j] - 2*np.pi
                
                if velocity[g+1][i][j] < -1*np.pi:
                    velocity[g+1][i][j] = velocity[g+1][i][j] + 2*np.pi

                if velocity[g+1][i][j] > vmax*2*np.pi:
                    velocity[g+1][i][j] = vmax*2*np.pi
                
                if velocity[g+1][i][j] < -vmax*2*np.pi:
                    velocity[g+1][i][j] = -vmax*2*np.pi

        count = count + 1

        c = np.array([0. for i in range(N)])
        s = np.array([0. for i in range(N)])

        for i in range(P):
            for j in range(N):
                c[j] = c[j] + np.real(np.cos(position[g][i][j])) / P
                s[j] = s[j] + np.real(np.sin(position[g][i][j])) / P

        best_policy = np.array([0. for i in range(N)])

        for i in range(N):
            if c[i] > 0 and s[i] > 0:
                best_policy[i] = np.real(np.arctan(s[i]/c[i]))
            if c[i] < 0:
                best_policy[i] = np.real(np.arctan(s[i]/c[i]) + 1*np.pi)
            if c[i] > 0 and s[i] < 0:
                best_policy[i] = np.real(np.arctan(s[i]/c[i]) + 2*np.pi)

        dispersion = np.array([0. for i in range(N)])

        for i in range(N):
            for j in range(P):

                if abs(best_policy[i] - position[g][j][i]) < 1*np.pi:
                    dispersion[i] = dispersion[i] + abs(best_policy[i] - position[g][j][i])                                 
            
                else:
                    dispersion[i] = dispersion[i] + 2*np.pi - abs(best_policy[i] - position[g][j][i])

            dispersion[i] = dispersion[i] / P

            if dispersion[i] < threshold * 2*np.pi:
                aux_counter = aux_counter + 1

        if aux_counter == N:
            break

    if count < G-1:
        print("The algorithm converged in", count, "iterations.\n")
    
    else:
        print("The algorithm didn't converge in", G, "iterations.\n")

    dispersion_avg = statistics.mean(dispersion)

    dispersion_std = statistics.stdev(dispersion)

    print("Dispersion Average: ", dispersion_avg, "  Dispersion Standard Deviation: ", dispersion_std, "\n")

    return best_policy